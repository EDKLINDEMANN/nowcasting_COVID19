---
title: "Digital Epidemiology - Statistical Learning"
subtitle: "Day 1 - Course Overview"
author: 
- "Stephan Gl√∂ckner"
- "email: stephan.gloeckner@helmholtz-hzi.de"
date: "Braunschweig, March 9th, 2020"
output:
  xaringan::moon_reader:
    nature:
      ratio: '14.6:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      navigation:
        scroll: false
    css: ["default", "css/style.css"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(broom)
theme_set(theme_light())
```



```{r literatur}
source(here::here("helper.R"))
library(RefManageR)
BibOptions(check.entries = FALSE, 
           bib.style = "authoryear", 
           style = "markdown",
           dashed = TRUE)
bib.file <- "lit01.bib"
bib <- ReadBib(bib.file)
```


class: inverse, center, middle

# Course Overview


---
# Introduction

```{r out.width = '55%', echo=FALSE, fig.align='center'}
knitr::include_graphics("pics/fb_rec.jpg")
```

* Netflix Recommendations
* Self Driving car
* Google Search fields
* Flight prices

... what else?

---
# Introduction

How does it learn?

---
# Introduction

How does it learn?

```{r out.width = '50%', echo=FALSE, fig.align='center'}
knitr::include_graphics("pics/ml_01.png")
```

---
# Introduction

How does it learn?

```{r out.width = '60%', echo=FALSE, fig.align='center'}
knitr::include_graphics("pics/ml_02.png")
```

---
# Introduction

```{r echo = FALSE, out.width = '35%',  fig.align='center'}
knitr::include_graphics("pics/machine-learning-cheet-sheet.png")
```
Source: Mathworks



---
# Introduction

How does it learn?

```{r out.width = '50%', echo=FALSE, fig.align='center'}
knitr::include_graphics("pics/ml_03.png")
```

Dateset-split ~60/40 or 70/30 ... with or without validation data.

.pull-left[
__Train Data__

* represents a subset of data
]

.pull-right[
__Test Data__

* never touch, stays as is
]

* Test data trains a alogrithm (log regression), with this trained algorithm it predicts the Test data.



---
# Introduction

How does it learn?

```{r fig.align='center', echo = FALSE, out.width = '50%'}
g1 <- read_csv("data/100m_finals.csv") %>% 
  ggplot(aes(olympic_year, time, color = gender, group = gender)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Winning times of the Olympic 100m Finals")
ggsave(plot = g1, filename = here::here("pics", "100m_raw.bmp"))
knitr::include_graphics("pics/100m_raw.bmp")
```

---
# Introduction

How does it learn?

```{r echo=TRUE, fig.height=4, fig.align='center'}
model <- read_csv("data/100m_finals.csv") %>% 
  lm(time ~ gender + olympic_year, data = .)

model %>% 
  tidy(conf.int = TRUE)
```

---
# Introduction

How does it learn?

```{r echo=TRUE, fig.height=4, fig.align='center'}
df_predict <- crossing(
  gender = c("mens", "womens"), 
  olympic_year = c(seq(2020, 2156, by = 4))
  )
df_predict %>% 
  head(5)
```

---
# Introduction

How does it learn?

```{r echo=TRUE, fig.height=4, fig.align='center'}
predict(model, df_predict) %>% 
  as_tibble() %>% 
  bind_cols(predicted_time = df_predict) %>% 
  spread(gender, value) %>% head(5)

```
---
# Introduction

How does it learn?

```{r fig.align='center', echo = FALSE, out.width = '50%'}
knitr::include_graphics("pics/100m_raw.bmp")
```

---
# Introduction

How does it learn?

```{r fig.align='center', echo = FALSE, out.width = '50%'}
g2 <- predict(model, df_predict) %>% 
  as_tibble() %>% 
  bind_cols(predicted_time = df_predict) %>% 
  rename(time = value) %>% 
  bind_rows(
    read_csv("data/100m_finals.csv")
  ) %>% 
  ggplot(aes(olympic_year, time, color = gender, group = gender)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Predicted winning times of the Olympic 100m Finals")
ggsave(plot = g2, filename = here::here("pics", "100m_pred.bmp"))
knitr::include_graphics("pics/100m_pred.bmp")
```


---
# What do we need?

1. Tidy data
2. Data preporcessing (`dplyr`, `tidyr`)
3. Data Transforming
4. Overview Algorithms

    4.1 Algorithms
    
    4.2 LASSO Regression (supervised)
    
    4.3 k-means Clustering (unsupervised)

5. Use Case: Text Mining
    
    5.2 Tokens, Stopwords, typo correction
    
    5.3 Feature Engineering
    
    5.4 Modelling



---
class: last-slide

Next - The last course



---
# Data quality

go to: https://gitlab.com/gstephan30/dq_hzi_course

or install:

https://git-scm.com/downloads
(for windows, add git to PATH - if not automatical)

and in you R terminal:

`git clone git@gitlab.com:gstephan30/dq_hzi_course.git`

__Webpage__

http://teaching.stephangloeckner.net/post/digital-epidemiology-i-data-quality/



